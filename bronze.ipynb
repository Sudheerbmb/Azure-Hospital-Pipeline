{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb6c4db",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "# Azure Event Hub Configuration\n",
    "event_hub_namespace = \"hospital-analytics-naamespace.servicebus.windows.net\"\n",
    "event_hub_name = \"hospital-analytics-eh\"\n",
    "event_hub_conn_str = dbutils.secrets.get(scope = \"hospitalanalyticsvaultscope\", key = \"eventhub-connection\")\n",
    "\n",
    "\n",
    "kafka_options = {\n",
    "    'kafka.bootstrap.servers': f\"{event_hub_namespace}:9093\",\n",
    "    'subscribe': event_hub_name,\n",
    "    'kafka.security.protocol': 'SASL_SSL',\n",
    "    'kafka.sasl.mechanism': 'PLAIN',\n",
    "    'kafka.sasl.jaas.config': f'kafkashaded.org.apache.kafka.common.security.plain.PlainLoginModule required username=\"$ConnectionString\" password=\"{event_hub_conn_str}\";',\n",
    "    'startingOffsets': 'latest',\n",
    "    'failOnDataLoss': 'false'\n",
    "}\n",
    "#Read from eventhub\n",
    "raw_df = (spark.readStream\n",
    "          .format(\"kafka\")\n",
    "          .options(**kafka_options)\n",
    "          .load()\n",
    "          )\n",
    "\n",
    "#Cast data to json\n",
    "json_df = raw_df.selectExpr(\"CAST(value AS STRING) as raw_json\")\n",
    "\n",
    "#ADLS configuration \n",
    "spark.conf.set(\n",
    "  \"fs.azure.account.key.hospitalstoraage.dfs.core.windows.net\",\n",
    "  dbutils.secrets.get(scope = \"hospitalanalyticsvaultscope\", key = \"storage-connection\")\n",
    "\n",
    ")\n",
    "\n",
    "bronze_path = \"abfss://bronze@hospitalstoraage.dfs.core.windows.net/patient_flow\"\n",
    "\n",
    "#Write stream to bronze\n",
    "(\n",
    "    json_df\n",
    "    .writeStream\n",
    "    .format(\"delta\")\n",
    "    .outputMode(\"append\")\n",
    "    .option(\"checkpointLocation\", \"dbfs:/mnt/bronze/_checkpoints/patient_flow\")\n",
    "    .start(bronze_path)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28596c84",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "\n",
    "# Azure Event Hub Configuration\n",
    "event_hub_namespace = \"<<Namespace_hostname>>\"\n",
    "event_hub_name=\"<<Eventhub_Name>>\"  \n",
    "event_hub_conn_str = \"<<Connection_string>>\"\n",
    "\n",
    "\n",
    "kafka_options = {\n",
    "    'kafka.bootstrap.servers': f\"{event_hub_namespace}:9093\",\n",
    "    'subscribe': event_hub_name,\n",
    "    'kafka.security.protocol': 'SASL_SSL',\n",
    "    'kafka.sasl.mechanism': 'PLAIN',\n",
    "    'kafka.sasl.jaas.config': f'kafkashaded.org.apache.kafka.common.security.plain.PlainLoginModule required username=\"$ConnectionString\" password=\"{event_hub_conn_str}\";',\n",
    "    'startingOffsets': 'latest',\n",
    "    'failOnDataLoss': 'false'\n",
    "}\n",
    "#Read from eventhub\n",
    "raw_df = (spark.readStream\n",
    "          .format(\"kafka\")\n",
    "          .options(**kafka_options)\n",
    "          .load()\n",
    "          )\n",
    "\n",
    "#Cast data to json\n",
    "json_df = raw_df.selectExpr(\"CAST(value AS STRING) as raw_json\")\n",
    "\n",
    "#ADLS configuration \n",
    "spark.conf.set(\n",
    "  \"fs.azure.account.key.<<Storageaccount_name>>.dfs.core.windows.net\",\n",
    "  \"<<Storage_Account_access_key>>\"\n",
    ")\n",
    "\n",
    "bronze_path = \"abfss://<<container>>@<<Storageaccount_name>>.core.windows.net/<<path>>\"\n",
    "\n",
    "#Write stream to bronze\n",
    "(\n",
    "    json_df\n",
    "    .writeStream\n",
    "    .format(\"delta\")\n",
    "    .outputMode(\"append\")\n",
    "    .option(\"checkpointLocation\", \"dbfs:/mnt/bronze/_checkpoints/patient_flow\")\n",
    "    .start(bronze_path)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
